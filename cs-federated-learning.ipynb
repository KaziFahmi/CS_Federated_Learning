{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2651938,"sourceType":"datasetVersion","datasetId":1591793}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/fahmikazimd/cs-federated-learning?scriptVersionId=172011814\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# **Imports**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport copy\n\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, f1_score","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.218389Z","iopub.execute_input":"2023-08-30T16:54:23.218855Z","iopub.status.idle":"2023-08-30T16:54:23.228609Z","shell.execute_reply.started":"2023-08-30T16:54:23.218821Z","shell.execute_reply":"2023-08-30T16:54:23.227041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Loading**","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('../input/drug-consumptions-uci/Drug_Consumption.csv')\ndata = data.drop('ID', axis=1)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.230874Z","iopub.execute_input":"2023-08-30T16:54:23.231306Z","iopub.status.idle":"2023-08-30T16:54:23.335055Z","shell.execute_reply.started":"2023-08-30T16:54:23.231273Z","shell.execute_reply":"2023-08-30T16:54:23.334135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data Cleaning and Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"# *Data Cleaning*\nIn the description of data, we are told that Semer is a fake drug that is used as a control. Since it is not a real drug those who claimed to have used Semer are assumed to be over claimers. We can not be sure these individuals have accurately recounted their drug use, therefore, we will remove these individuals from the data frame.\n","metadata":{}},{"cell_type":"code","source":"print(f'Original shape of data with {data.shape[0]} rows and {data.shape[1]} columns')\n# Removing Overclaimers\ndata.query(\"Semer != 'CL0'\") \ndata = data.drop(data[data['Semer'] != 'CL0'].index)\nprint(f'Shape of data without overclaimers with {data.shape[0]} rows and {data.shape[1]} columns')","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.33674Z","iopub.execute_input":"2023-08-30T16:54:23.337347Z","iopub.status.idle":"2023-08-30T16:54:23.362902Z","shell.execute_reply.started":"2023-08-30T16:54:23.337314Z","shell.execute_reply":"2023-08-30T16:54:23.361197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Encoding*\n\nEncoding the features as the following: \n\n* Age:\n    * 0 = 18-24\n    * 1 = 25-34\n    * 2 = 35-44\n    * 3 = 45-54\n    * 4 = 55-64\n    * 5 = 65+\n* Gender:\n    * 0 = F\n    * 1 = M\n* Education:\n    * 0 = Left school before 16 years\n    * 1 = Left school at 16 years\n    * 2 = Left school at 17 years\n    * 3 = Left school at 18 years\n    * 4 = Some college or university, no certificate or degree\n    * 5 = Professional certificate/ diploma\n    * 6 = University degree\n    * 7 = Masters degree\n    * 8 = Doctorate degree\n* Country:\n    * 0 = Australia\n    * 1 = Canada\n    * 2 = New Zealand\n    * 3 = Other\n    * 4 = Republic of Ireland\n    * 5 = UK\n    * 6 = USA\n* Ethincity:\n    * 0 = Asian\n    * 1 = Black\n    * 2 = Mixed-Black/Asian\n    * 3 = Mixed-White/Asian\n    * 4 = Mixed-White/Black\n    * 5 = Other\n    * 6 = White\n* Drug Use:\n    * 0 = never used the drug\n    * 1 = used it over a decade ago\n    * 2 = in the last decade\n    * 3 = used in the last year\n    * 4 = used in the last month\n    * 5 = used in the last week\n    * 6 = used in the last day","metadata":{}},{"cell_type":"code","source":"def encode(df, column, encoding): \n    df = df.copy()\n    df[column] = df[column].apply(lambda x: encoding[x]).astype(np.int64)\n    return df","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.364828Z","iopub.execute_input":"2023-08-30T16:54:23.365305Z","iopub.status.idle":"2023-08-30T16:54:23.374524Z","shell.execute_reply.started":"2023-08-30T16:54:23.365268Z","shell.execute_reply":"2023-08-30T16:54:23.37283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Age\nage_encoding = {\n    '18-24': 0, \n    '25-34': 1, \n    '35-44': 2, \n    '45-54': 3, \n    '55-64': 4, \n    '65+': 5\n}\n\ndata = encode(data, 'Age', age_encoding)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.378517Z","iopub.execute_input":"2023-08-30T16:54:23.379014Z","iopub.status.idle":"2023-08-30T16:54:23.393287Z","shell.execute_reply.started":"2023-08-30T16:54:23.378946Z","shell.execute_reply":"2023-08-30T16:54:23.391996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Gender\ngender_encoding = {\n    'M': 1,\n    'F': 0\n}\ndata = encode(data, 'Gender', gender_encoding)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.395246Z","iopub.execute_input":"2023-08-30T16:54:23.395666Z","iopub.status.idle":"2023-08-30T16:54:23.408037Z","shell.execute_reply.started":"2023-08-30T16:54:23.39563Z","shell.execute_reply":"2023-08-30T16:54:23.406752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Education\neducation_encoding = {\n    'Left school before 16 years': 0, \n    'Left school at 16 years': 1, \n    'Left school at 17 years': 2, \n    'Left school at 18 years': 3,\n    'Some college or university, no certificate or degree': 4,\n    'Professional certificate/ diploma': 5,\n    'University degree': 6,\n    'Masters degree': 7,\n    'Doctorate degree': 8\n}\ndata = encode(data, 'Education', education_encoding)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.409855Z","iopub.execute_input":"2023-08-30T16:54:23.410319Z","iopub.status.idle":"2023-08-30T16:54:23.425232Z","shell.execute_reply.started":"2023-08-30T16:54:23.410281Z","shell.execute_reply":"2023-08-30T16:54:23.423847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Country\ncountry_encoding = {\n    'Australia': 0,\n    'Canada': 1,\n    'New Zealand': 2,\n    'Other': 3,\n    'Republic of Ireland': 4,\n    'UK': 5,\n    'USA': 6\n}\ndata = encode(data, 'Country', country_encoding)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.427083Z","iopub.execute_input":"2023-08-30T16:54:23.427569Z","iopub.status.idle":"2023-08-30T16:54:23.442241Z","shell.execute_reply.started":"2023-08-30T16:54:23.427526Z","shell.execute_reply":"2023-08-30T16:54:23.44077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Ethnicity\nethnicity_encoding = {\n    'Asian': 0,\n    'Black': 1,\n    'Mixed-Black/Asian': 2,\n    'Mixed-White/Asian': 3,\n    'Mixed-White/Black': 4,\n    'Other': 5,\n    'White': 6\n}\ndata = encode(data, 'Ethnicity', ethnicity_encoding)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.444096Z","iopub.execute_input":"2023-08-30T16:54:23.444553Z","iopub.status.idle":"2023-08-30T16:54:23.463943Z","shell.execute_reply.started":"2023-08-30T16:54:23.444513Z","shell.execute_reply":"2023-08-30T16:54:23.462477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Drug use\ndrugs = ['Alcohol',\n         'Amyl',\n         'Amphet',\n         'Benzos',\n         'Choc',\n         'Caff',\n         'Cannabis',\n         'Coke',\n         'Crack',\n         'Ecstasy',\n         'Heroin',\n         'Ketamine',\n         'Legalh',\n         'LSD',\n         'Meth',\n         'Mushrooms',\n         'Nicotine',\n         'VSA'    ]\ndrug_use_encoding = {\n    'CL0': 0,\n    'CL1': 0,\n    'CL2': 1,\n    'CL3': 1,\n    'CL4': 1,\n    'CL5': 1,\n    'CL6': 1\n}\nfor drug in drugs:\n    data = encode(data, drug, drug_use_encoding)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.466403Z","iopub.execute_input":"2023-08-30T16:54:23.466798Z","iopub.status.idle":"2023-08-30T16:54:23.526466Z","shell.execute_reply.started":"2023-08-30T16:54:23.466766Z","shell.execute_reply":"2023-08-30T16:54:23.525323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.533272Z","iopub.execute_input":"2023-08-30T16:54:23.533635Z","iopub.status.idle":"2023-08-30T16:54:23.565075Z","shell.execute_reply.started":"2023-08-30T16:54:23.533604Z","shell.execute_reply":"2023-08-30T16:54:23.56391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Removing Unnecessary Columns*","metadata":{}},{"cell_type":"code","source":"# Removing overclaimer signifying columns\ndata = data.drop(['Semer'], axis=1)\ndata = data.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.566727Z","iopub.execute_input":"2023-08-30T16:54:23.567149Z","iopub.status.idle":"2023-08-30T16:54:23.574967Z","shell.execute_reply.started":"2023-08-30T16:54:23.567116Z","shell.execute_reply":"2023-08-30T16:54:23.574035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since Coke and Crack are both just different types of Cocaine, we merge them together and remove the original Coke and Crack columns","metadata":{}},{"cell_type":"code","source":"# Merging the Coke and Crack columns\ndata['both_user'] = data[['Coke', 'Crack']].iloc[:].sum(axis=1)\ndata['Cocaine'] = data['both_user'].apply(lambda x: 1 if x > 0 else 0)\ndata = data.drop(['both_user', 'Coke', 'Crack'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.577217Z","iopub.execute_input":"2023-08-30T16:54:23.577824Z","iopub.status.idle":"2023-08-30T16:54:23.596704Z","shell.execute_reply.started":"2023-08-30T16:54:23.577775Z","shell.execute_reply":"2023-08-30T16:54:23.595201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Finding the illegal drug with most data\nillegal_drugs = ['Amyl', 'Amphet','Cocaine', 'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms', 'VSA']\nhighest_used_drug = 'Amyl'\nhighest_count = 0\nfor drug in illegal_drugs:\n    users = data[drug].sum()\n    if users > highest_count:\n        highest_used_drug = drug\n        highest_count = users\n\nprint(highest_used_drug, highest_count)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.598418Z","iopub.execute_input":"2023-08-30T16:54:23.598773Z","iopub.status.idle":"2023-08-30T16:54:23.616674Z","shell.execute_reply.started":"2023-08-30T16:54:23.598743Z","shell.execute_reply":"2023-08-30T16:54:23.615431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = data.corr(numeric_only=True)\n# print(corr['Legalh'])\nlow_corr = []\nfor key, value in corr['Legalh'].items():\n    if abs(value) < 0.30:\n        low_corr.append(key)\nprint(low_corr)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.61825Z","iopub.execute_input":"2023-08-30T16:54:23.618799Z","iopub.status.idle":"2023-08-30T16:54:23.643357Z","shell.execute_reply.started":"2023-08-30T16:54:23.618766Z","shell.execute_reply":"2023-08-30T16:54:23.641842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rem = ['Education', 'Country', 'Ethnicity', 'Alcohol','Caff', 'Choc'] # excluding the score values and other drugs\nfor column in rem:\n    data = data.drop(column, axis=1)\n# corr = data.corr(numeric_only=True)\n# print(corr['Legalh'])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.645075Z","iopub.execute_input":"2023-08-30T16:54:23.645453Z","iopub.status.idle":"2023-08-30T16:54:23.65831Z","shell.execute_reply.started":"2023-08-30T16:54:23.645423Z","shell.execute_reply":"2023-08-30T16:54:23.656841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.660475Z","iopub.execute_input":"2023-08-30T16:54:23.660938Z","iopub.status.idle":"2023-08-30T16:54:23.701027Z","shell.execute_reply.started":"2023-08-30T16:54:23.660893Z","shell.execute_reply":"2023-08-30T16:54:23.699513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Creating Centers and Preprocessing*","metadata":{}},{"cell_type":"code","source":"print(\"Size:\" ,data.shape[0])\ndata.sample(frac=1, random_state=1)\ncenters = {}\nfor i in range(4):\n    center_name = 'center_' + str(i+1)\n    centers[center_name] = data.iloc[i*len(data) // 4: (i+1)*len(data) // 4]\n\nprint(\"Center 1 size:\", centers[\"center_1\"].shape[0])\nprint(\"Center 2 size:\", centers[\"center_2\"].shape[0])\nprint(\"Center 3 size:\", centers[\"center_3\"].shape[0])\nprint(\"Center 4 size:\", centers[\"center_4\"].shape[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.703505Z","iopub.execute_input":"2023-08-30T16:54:23.704064Z","iopub.status.idle":"2023-08-30T16:54:23.717791Z","shell.execute_reply.started":"2023-08-30T16:54:23.704019Z","shell.execute_reply":"2023-08-30T16:54:23.716397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for center, df in centers.items():\n    # seperating label from features\n    y = df['Legalh']\n    X = df.drop('Legalh', axis=1)\n    # Train-test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n    # Scale X\n    scaler = StandardScaler()\n    scaler.fit(X_train)\n    X_train = pd.DataFrame(scaler.transform(X_train), \n                           index=X_train.index, \n                           columns=X_train.columns)\n    X_test = pd.DataFrame(scaler.transform(X_test), \n                          index=X_test.index, \n                          columns=X_test.columns)\n    centers[center] = {\n        'X_train': X_train,\n        'X_test': X_test,\n        'y_train': y_train,\n        'y_test': y_test\n    }","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.719393Z","iopub.execute_input":"2023-08-30T16:54:23.719882Z","iopub.status.idle":"2023-08-30T16:54:23.768398Z","shell.execute_reply.started":"2023-08-30T16:54:23.719851Z","shell.execute_reply":"2023-08-30T16:54:23.766935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"centers['center_1']['X_train'].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.770173Z","iopub.execute_input":"2023-08-30T16:54:23.770654Z","iopub.status.idle":"2023-08-30T16:54:23.804971Z","shell.execute_reply.started":"2023-08-30T16:54:23.770612Z","shell.execute_reply":"2023-08-30T16:54:23.803511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"centers['center_2']['X_train'].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.806781Z","iopub.execute_input":"2023-08-30T16:54:23.807306Z","iopub.status.idle":"2023-08-30T16:54:23.839158Z","shell.execute_reply.started":"2023-08-30T16:54:23.807259Z","shell.execute_reply":"2023-08-30T16:54:23.837642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"centers['center_3']['X_train'].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.840989Z","iopub.execute_input":"2023-08-30T16:54:23.841453Z","iopub.status.idle":"2023-08-30T16:54:23.877812Z","shell.execute_reply.started":"2023-08-30T16:54:23.841411Z","shell.execute_reply":"2023-08-30T16:54:23.87673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"centers['center_4']['X_train'].head()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.879383Z","iopub.execute_input":"2023-08-30T16:54:23.87976Z","iopub.status.idle":"2023-08-30T16:54:23.917834Z","shell.execute_reply.started":"2023-08-30T16:54:23.87973Z","shell.execute_reply":"2023-08-30T16:54:23.916885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Training**","metadata":{}},{"cell_type":"markdown","source":"# *Function to show the results*","metadata":{}},{"cell_type":"code","source":"def validate(models, centers):\n    row = 0\n    fig, axes = plt.subplots(nrows=len(centers.keys()), ncols=2, figsize=(12, 32))\n    \n    for center in centers.keys():\n        X_test = centers[center]['X_test']\n        y_test = centers[center]['y_test']\n        \n        concerned_models = {\n            center: models[center], \n            'FedAvg': models['FedAvg'], \n            'FedProx': models['FedProx'],\n            'FedAdam': models['FedAdam']\n        }\n        \n        accuracy_values = {}  # Dictionary to store accuracy values for each model\n        f1_score_values = {}  # Dictionary to store F1 score values for each model\n        for model in concerned_models.keys():\n            \n            # Finding Accuracy\n            yhat = concerned_models[model].predict(X_test)\n            acc = accuracy_score(y_test, yhat)\n            accuracy_values[model] = acc * 100\n            \n            # Finding F1 Score\n            yhat = concerned_models[model].predict(X_test)\n            f1 = f1_score(y_test, yhat, pos_label=1)\n            f1_score_values[model] = f1\n            \n        print(\"Accuracy:\", accuracy_values)\n        print(\"F1 scores:\", f1_score_values)\n        model_names = list(concerned_models.keys())\n        x = np.arange(len(model_names))\n        \n        # Plot Accuracy\n        ax1 = axes[row][0]\n        ax1.bar(x, accuracy_values.values(), label='Accuracy', color='blue', alpha=0.7)\n        ax1.set_xticks(x)\n        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n        ax1.set_ylabel('Accuracy')\n        ax1.set_title(f'Accuracy and F1 Score for Different Models on the test set of {center}')\n        \n        # Plot F1 Score\n        ax2 = axes[row][1]\n        ax2.bar(x, f1_score_values.values(), label='F1 Score', color='green', alpha=0.7)\n        ax2.set_xticks(x)\n        ax2.set_xticklabels(model_names, rotation=45, ha='right')\n        ax2.set_ylabel('F1 Score')\n        row +=1\n    \n    plt.tight_layout()\n    plt.show()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.920232Z","iopub.execute_input":"2023-08-30T16:54:23.920582Z","iopub.status.idle":"2023-08-30T16:54:23.93729Z","shell.execute_reply.started":"2023-08-30T16:54:23.920554Z","shell.execute_reply":"2023-08-30T16:54:23.935741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Logistic Regression*","metadata":{}},{"cell_type":"code","source":"# Aggregation functions\n\ndef FedAvgLogistic(models):\n    # Initialize the global model with the first model from the dictionary\n    global_model = models[list(models.keys())[0]]\n    \n    # Loop through the other models and add their parameters to the global model\n    for center, model in models.items():\n        if model != global_model:\n            global_model.coef_ += model.coef_\n            global_model.intercept_ += model.intercept_\n    \n    # Compute the average\n    global_model.coef_ /= len(models)\n    global_model.intercept_ /= len(models)\n    \n    return global_model\n\ndef FedProxLogistic(models, learning_rate=0.01, regularization_strength=0.1):\n    # Use the first model from the dictionary as the global model\n    global_model = models[list(models.keys())[0]]\n    \n    # Apply proximal gradient descent update\n    for center, model in models.items():\n        if model != global_model:\n            gradient = model.coef_  # Gradient of the local model\n        \n            # Apply proximal gradient descent update\n            global_model.coef_ -= learning_rate * (gradient + regularization_strength * global_model.coef_)\n            global_model.intercept_ -= learning_rate * (model.intercept_ + regularization_strength * global_model.intercept_)\n    \n    return global_model\n\ndef FedAdamLogistic(models, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-7, regularization_strength=0.1):\n    # Initialize moment estimates for Adam\n    m = np.zeros(models[list(models.keys())[0]].coef_.shape)\n    v = np.zeros(models[list(models.keys())[0]].coef_.shape)\n    t = 0\n    \n    # Use the first model from the dictionary as the global model\n    global_model = models[list(models.keys())[0]]\n    \n    for center, model in models.items():\n        t += 1\n        gradient = model.coef_  # Gradient of the local model\n        \n        # Update moment estimates\n        m = beta1 * m + (1 - beta1) * gradient\n        v = beta2 * v + (1 - beta2) * (gradient ** 2)\n        \n        # Bias correction\n        m_hat = m / (1 - beta1 ** t)\n        v_hat = v / (1 - beta2 ** t)\n        \n        # Check if the model is not the same as the global model before updating\n        if model != global_model:\n            # Update the global model using Adam\n            global_model.coef_ -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n            global_model.intercept_ -= learning_rate * (model.intercept_ + regularization_strength * global_model.intercept_)\n    \n    return global_model","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.939497Z","iopub.execute_input":"2023-08-30T16:54:23.939969Z","iopub.status.idle":"2023-08-30T16:54:23.964447Z","shell.execute_reply.started":"2023-08-30T16:54:23.939914Z","shell.execute_reply":"2023-08-30T16:54:23.963219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the models\nlogistic_regression_models = {}\nfor center in centers.keys():\n    X_train = centers[center]['X_train']\n    y_train = centers[center]['y_train']\n    \n    model = LogisticRegression()\n    model.fit(X_train, y_train)\n    logistic_regression_models[center] = model","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:23.96604Z","iopub.execute_input":"2023-08-30T16:54:23.967675Z","iopub.status.idle":"2023-08-30T16:54:24.028154Z","shell.execute_reply.started":"2023-08-30T16:54:23.967621Z","shell.execute_reply":"2023-08-30T16:54:24.026699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Federated learning\ntemp_logistic = {key: value for key, value in logistic_regression_models.items()}\n\nlogistic_regression_models['FedAvg'] = FedAvgLogistic(temp_logistic)\nlogistic_regression_models['FedProx'] = FedProxLogistic(temp_logistic)\nlogistic_regression_models['FedAdam'] = FedAdamLogistic(temp_logistic)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:24.02967Z","iopub.execute_input":"2023-08-30T16:54:24.030064Z","iopub.status.idle":"2023-08-30T16:54:24.037741Z","shell.execute_reply.started":"2023-08-30T16:54:24.029998Z","shell.execute_reply":"2023-08-30T16:54:24.036254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validate(logistic_regression_models, centers)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:24.039768Z","iopub.execute_input":"2023-08-30T16:54:24.040492Z","iopub.status.idle":"2023-08-30T16:54:26.499313Z","shell.execute_reply.started":"2023-08-30T16:54:24.040459Z","shell.execute_reply":"2023-08-30T16:54:26.498212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *Naive Bayes*","metadata":{}},{"cell_type":"code","source":"def FedAvgNB(models):\n    global_model = models[list(models.keys())[0]]\n    for center in models.keys():\n        if center != list(models.keys())[0]:\n            global_model.class_prior_ += models[center].class_prior_\n            global_model.theta_ += models[center].theta_\n    global_model.class_prior_ /= len(models)\n    global_model.theta_ /= len(models)\n    return global_model\n\ndef FedProxNB(models, learning_rate=0.01, penalty=0.01):\n    global_model = models[list(models.keys())[0]]\n    for center in models.keys():\n        if center != list(models.keys())[0]:\n            global_model.class_prior_ = (1 - learning_rate * penalty) * global_model.class_prior_ + learning_rate * models[center].class_prior_\n            global_model.theta_ = (1 - learning_rate * penalty) * global_model.theta_ + learning_rate * models[center].theta_\n    return global_model\n\n\ndef FedAdamNB(models, learning_rate=0.01, beta1=0.9, beta2=0.999, epsilon=1e-8):\n    global_model = models[list(models.keys())[0]]\n    m = [0] * len(global_model.class_prior_)\n    v = [0] * len(global_model.class_prior_)\n    t = 0\n    for center in models.keys():\n        if center != list(models.keys())[0]:\n            t += 1\n            for layer in range(len(global_model.class_prior_)):\n                m[layer] = beta1 * m[layer] + (1 - beta1) * models[center].class_prior_[layer]\n                v[layer] = beta2 * v[layer] + (1 - beta2) * (models[center].class_prior_[layer] ** 2)\n                m_hat = m[layer] / (1 - beta1 ** t)\n                v_hat = v[layer] / (1 - beta2 ** t)\n                global_model.class_prior_[layer] -= (\n                    learning_rate * m_hat / (epsilon + v_hat ** 0.5)\n                )\n                global_model.theta_[layer] -= (\n                    learning_rate * m_hat / (epsilon + v_hat ** 0.5)\n                )\n    \n    return global_model  ","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:26.506159Z","iopub.execute_input":"2023-08-30T16:54:26.507153Z","iopub.status.idle":"2023-08-30T16:54:26.524563Z","shell.execute_reply.started":"2023-08-30T16:54:26.507107Z","shell.execute_reply":"2023-08-30T16:54:26.523097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the models\n\nnaive_bayes_models = {}\n\nfor center in centers.keys():\n    X_train = centers[center]['X_train']\n    y_train = centers[center]['y_train']\n    naive_bayes = GaussianNB()\n    naive_bayes.fit(X_train, y_train)\n    naive_bayes_models[center] = naive_bayes","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:26.526285Z","iopub.execute_input":"2023-08-30T16:54:26.52667Z","iopub.status.idle":"2023-08-30T16:54:26.572037Z","shell.execute_reply.started":"2023-08-30T16:54:26.526639Z","shell.execute_reply":"2023-08-30T16:54:26.570878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Federated learning\ntemp_nbm = {key: value for key, value in naive_bayes_models.items()}\n\nnaive_bayes_models['FedAvg'] = FedAvgNB(temp_nbm)\nnaive_bayes_models['FedProx'] = FedProxNB(temp_nbm)\nnaive_bayes_models['FedAdam'] = FedAdamNB(temp_nbm)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:26.573489Z","iopub.execute_input":"2023-08-30T16:54:26.574263Z","iopub.status.idle":"2023-08-30T16:54:26.586303Z","shell.execute_reply.started":"2023-08-30T16:54:26.574036Z","shell.execute_reply":"2023-08-30T16:54:26.584948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validate(naive_bayes_models, centers)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:26.588042Z","iopub.execute_input":"2023-08-30T16:54:26.588435Z","iopub.status.idle":"2023-08-30T16:54:28.738549Z","shell.execute_reply.started":"2023-08-30T16:54:26.588401Z","shell.execute_reply":"2023-08-30T16:54:28.737117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# *K means Clustering*","metadata":{}},{"cell_type":"code","source":"# Trying to find number of clusters\n\nfor center in centers.keys():\n    X_train = centers[center]['X_train']\n    y_train = centers[center]['y_train']\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X_train)\n    plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_train, cmap='viridis') \n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.title('PCA - Cluster Visualization')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:28.740508Z","iopub.execute_input":"2023-08-30T16:54:28.740986Z","iopub.status.idle":"2023-08-30T16:54:29.992472Z","shell.execute_reply.started":"2023-08-30T16:54:28.740924Z","shell.execute_reply":"2023-08-30T16:54:29.991003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aggregation Functions\n\ndef FedAvgKMeans(models):\n    # Initialize the global model with the first model from the dictionary\n    global_model = models[list(models.keys())[0]]\n    \n    # Loop through the other models and add their cluster centers to the global model\n    for country, model in models.items():\n        if model != global_model:\n            global_model.cluster_centers_ += model.cluster_centers_\n    \n    # Compute the average\n    global_model.cluster_centers_ /= len(models)\n    \n    return global_model\n\ndef FedProxKMeans(models, learning_rate=0.01, regularization_strength=0.1):\n    # Use the first model from the dictionary as the global model\n    global_model = models[list(models.keys())[0]]\n    \n    # Apply proximal gradient descent update\n    for country, model in models.items():\n        if model != global_model:\n            gradient = model.cluster_centers_  # Gradient of the local model\n        \n            # Apply proximal gradient descent update\n            global_model.cluster_centers_ -= learning_rate * (gradient + regularization_strength * global_model.cluster_centers_)\n    \n    return global_model\n\ndef FedAdamKMeans(models, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-7, regularization_strength=0.1):\n    # Initialize moment estimates for Adam\n    m = np.zeros(models[list(models.keys())[0]].cluster_centers_.shape)\n    v = np.zeros(models[list(models.keys())[0]].cluster_centers_.shape)\n    t = 0\n    \n    # Use the first model from the dictionary as the global model\n    global_model = models[list(models.keys())[0]]\n    \n    for country, model in models.items():\n        t += 1\n        gradient = model.cluster_centers_  # Gradient of the local model\n        \n        # Update moment estimates\n        m = beta1 * m + (1 - beta1) * gradient\n        v = beta2 * v + (1 - beta2) * (gradient ** 2)\n        \n        # Bias correction\n        m_hat = m / (1 - beta1 ** t)\n        v_hat = v / (1 - beta2 ** t)\n        \n        # Check if the model is not the same as the global model before updating\n        if model != global_model:\n            # Update the global model using Adam\n            global_model.cluster_centers_ -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n    \n    return global_model","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:29.994442Z","iopub.execute_input":"2023-08-30T16:54:29.994877Z","iopub.status.idle":"2023-08-30T16:54:30.013273Z","shell.execute_reply.started":"2023-08-30T16:54:29.99484Z","shell.execute_reply":"2023-08-30T16:54:30.011761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the models\nkmeans_models = {}\n\nfor country in centers.keys():\n    X_train = centers[country]['X_train']\n    y_train = centers[country]['y_train']\n    \n    # Train K means clustering model\n    kmeans = KMeans(n_clusters=2, n_init=10, random_state=1)  # You can adjust the number of clusters\n    kmeans.fit(X_train)\n    kmeans_models[country] = kmeans","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:30.015433Z","iopub.execute_input":"2023-08-30T16:54:30.015931Z","iopub.status.idle":"2023-08-30T16:54:30.163738Z","shell.execute_reply.started":"2023-08-30T16:54:30.015886Z","shell.execute_reply":"2023-08-30T16:54:30.162793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Federated learning\ntemp_kmeans = {key: value for key, value in kmeans_models.items()}\n\nkmeans_models['FedAvg'] = FedAvgKMeans(temp_kmeans)\nkmeans_models['FedProx'] = FedProxKMeans(temp_kmeans)\nkmeans_models['FedAdam'] = FedAdamKMeans(temp_kmeans)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:30.168284Z","iopub.execute_input":"2023-08-30T16:54:30.171248Z","iopub.status.idle":"2023-08-30T16:54:30.179172Z","shell.execute_reply.started":"2023-08-30T16:54:30.171203Z","shell.execute_reply":"2023-08-30T16:54:30.178185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validate(kmeans_models, centers)","metadata":{"execution":{"iopub.status.busy":"2023-08-30T16:54:30.180549Z","iopub.execute_input":"2023-08-30T16:54:30.180903Z","iopub.status.idle":"2023-08-30T16:54:32.171847Z","shell.execute_reply.started":"2023-08-30T16:54:30.180871Z","shell.execute_reply":"2023-08-30T16:54:32.170727Z"},"trusted":true},"execution_count":null,"outputs":[]}]}